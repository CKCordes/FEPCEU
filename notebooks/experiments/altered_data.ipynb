{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0170f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f273b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/sedroc/Bachelor/FEPCEU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c6c7b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sedroc/Bachelor/FEPCEU/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "from enhanced_experiment import EnhancedTimeSeriesExperiment\n",
    "from models.arima import Arima\n",
    "from models.baseline import Baseline\n",
    "from models.lgbm import LGBM\n",
    "from models.neuralproph import Neuralprophet\n",
    "from models.timegpt import TimeGPT\n",
    "\n",
    "from data.data_retriever import Dataretreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63b8bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'BASELINE': Baseline(),\n",
    "    'LGBM': LGBM(),\n",
    "    'ARIMA': Arima(order=[1,0,1], seasonal_order=[1,1,1,24]),\n",
    "    'NEURALPROPHET': Neuralprophet(),\n",
    "    'TimeGPT': TimeGPT()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e0224",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "X reduction. Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataretreiver(reduce='pca_kmeans', debug=False, reduction_num_cols=12)\n",
    "df = data.combined\n",
    "# Initialize the experiment\n",
    "experiment = EnhancedTimeSeriesExperiment(\n",
    "    models=models,\n",
    "    target_column='price',\n",
    "    forecast_horizon=192,\n",
    "    n_splits=5,\n",
    "    step_size=192 # 8 days are skipped between each forecast.\n",
    ")\n",
    "# Run the experiments with these custom combinations\n",
    "experiment.run_feature_group_experiments(\n",
    "    df=df,\n",
    "    add_all_columns=True,\n",
    "    add_base_columns=False,\n",
    ")\n",
    "results_df_MAE = experiment.summarize_feature_group_results(metric='MAE')\n",
    "results_df_MSE = experiment.summarize_feature_group_results(metric='RMSE')\n",
    "results_df_time = experiment.summarize_feature_group_results(metric='elapsed_time')\n",
    "print('='*50)\n",
    "print(\"MAE:\")\n",
    "print(results_df_MAE)\n",
    "print(\"RMSE\")\n",
    "print(results_df_MSE)\n",
    "print(\"Elapsed time\")\n",
    "print(results_df_time)\n",
    "print('='*50)\n",
    "\n",
    "experiment.save_feature_group_results_to_csv(f\"../results/manipulate/original.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20be029",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "X reduction. slightly manipulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066f7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified area columns: {'sun': {23: 'sun_area_23', 8: 'sun_area_8', 34: 'sun_area_34', 9: 'sun_area_9', 16: 'sun_area_16', 31: 'sun_area_31', 25: 'sun_area_25', 33: 'sun_area_33', 6: 'sun_area_6', 2: 'sun_area_2', 35: 'sun_area_35', 17: 'sun_area_17'}, 'wind': {22: 'wind_area_22', 34: 'wind_area_34', 8: 'wind_area_8', 9: 'wind_area_9', 16: 'wind_area_16', 32: 'wind_area_32', 24: 'wind_area_24', 31: 'wind_area_31', 6: 'wind_area_6', 2: 'wind_area_2', 15: 'wind_area_15', 5: 'wind_area_5'}}\n",
      "Cross-validation splits with sliding window:\n",
      "Split 1: Train start = 2024-01-01 00:00:00 (index 0), Train end = 2024-06-29 20:00:00 (index 4340), Test end = 2024-07-07 19:00:00 (index 4531), Training size = 4340\n",
      "Split 2: Train start = 2024-01-09 00:00:00 (index 192), Train end = 2024-07-07 20:00:00 (index 4532), Test end = 2024-07-15 19:00:00 (index 4723), Training size = 4340\n",
      "Split 3: Train start = 2024-01-17 00:00:00 (index 384), Train end = 2024-07-15 20:00:00 (index 4724), Test end = 2024-07-23 19:00:00 (index 4915), Training size = 4340\n",
      "Split 4: Train start = 2024-01-25 00:00:00 (index 576), Train end = 2024-07-23 20:00:00 (index 4916), Test end = 2024-07-31 19:00:00 (index 5107), Training size = 4340\n",
      "Split 5: Train start = 2024-02-02 00:00:00 (index 768), Train end = 2024-07-31 20:00:00 (index 5108), Test end = 2024-08-08 19:00:00 (index 5299), Training size = 4340\n",
      "\n",
      "================================================================================\n",
      "Running experiment for feature group: all_areas\n",
      "Using columns: ['sun_area_23', 'sun_area_8', 'sun_area_34', 'sun_area_9', 'sun_area_16', 'sun_area_31', 'sun_area_25', 'sun_area_33', 'sun_area_6', 'sun_area_2', 'sun_area_35', 'sun_area_17', 'wind_area_22', 'wind_area_34', 'wind_area_8', 'wind_area_9', 'wind_area_16', 'wind_area_32', 'wind_area_24', 'wind_area_31', 'wind_area_6', 'wind_area_2', 'wind_area_15', 'wind_area_5']\n",
      "Running CV split 1/5 for feature group all_areas\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Overall Renewable Correlation:\n",
      "Original correlation: -0.5436\n",
      "Adjusted correlation: -0.5663\n",
      "Change: -0.0227\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Wind Correlation:\n",
      "Original correlation between prices and wind: -0.5286\n",
      "Adjusted correlation between prices and wind: -0.5418\n",
      "Change: -0.0132\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Sun Correlation:\n",
      "Original correlation between prices and sun: -0.3136\n",
      "Adjusted correlation between prices and sun: -0.3344\n",
      "Change: -0.0208\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 198.803: 100%|██████████| 20/20 [02:19<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'n_estimators': 1000, 'max_depth': 3, 'min_data_in_leaf': 25, 'learning_rate': 0.3237547055740914, 'feature_fraction': 0.97233217839372, 'max_bin': 249, 'reg_alpha': 0.8247581533979889, 'reg_lambda': 0.2651957480262184}\n",
      "  Backtesting metric: 198.80331642068145\n",
      "Fitting ARIMA model with order: [1, 0, 1] and seasonal order: [1, 1, 1, 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /home/sedroc/Bachelor/FEPCEU/.venv/lib/python3.13/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "\n",
      "WARNING:py.warnings:/home/sedroc/Bachelor/FEPCEU/.venv/lib/python3.13/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = Dataretreiver(reduce='pca_kmeans', debug=False, reduction_num_cols=12)\n",
    "df = data.combined\n",
    "# Initialize the experiment\n",
    "experiment = EnhancedTimeSeriesExperiment(\n",
    "    models=models,\n",
    "    target_column='price',\n",
    "    forecast_horizon=192,\n",
    "    n_splits=5,\n",
    "    step_size=192 # 8 days are skipped between each forecast.\n",
    ")\n",
    "# Run the experiments with these custom combinations\n",
    "experiment.run_feature_group_experiments(\n",
    "    df=df,\n",
    "    add_all_columns=True,\n",
    "    add_base_columns=False,\n",
    "    manipulate=True,\n",
    "    manipulate_factor_sun=0.1,\n",
    "    manipulate_factor_wind=0.1,\n",
    ")\n",
    "results_df_MAE = experiment.summarize_feature_group_results(metric='MAE')\n",
    "results_df_MSE = experiment.summarize_feature_group_results(metric='RMSE')\n",
    "results_df_time = experiment.summarize_feature_group_results(metric='elapsed_time')\n",
    "print('='*50)\n",
    "print(\"MAE:\")\n",
    "print(results_df_MAE)\n",
    "print(\"RMSE\")\n",
    "print(results_df_MSE)\n",
    "print(\"Elapsed time\")\n",
    "print(results_df_time)\n",
    "print('='*50)\n",
    "\n",
    "experiment.save_feature_group_results_to_csv(f\"../results/manipulate/point1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e27f880",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "X reduction. More manipulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e957964",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataretreiver(reduce='pca_kmeans', debug=False, reduction_num_cols=12)\n",
    "df = data.combined\n",
    "# Initialize the experiment\n",
    "experiment = EnhancedTimeSeriesExperiment(\n",
    "    models=models,\n",
    "    target_column='price',\n",
    "    forecast_horizon=192,\n",
    "    n_splits=5,\n",
    "    step_size=192 # 8 days are skipped between each forecast.\n",
    ")\n",
    "# Run the experiments with these custom combinations\n",
    "experiment.run_feature_group_experiments(\n",
    "    df=df,\n",
    "    add_all_columns=True,\n",
    "    add_base_columns=False,\n",
    "    manipulate=True,\n",
    "    manipulate_factor_sun=0.3,\n",
    "    manipulate_factor_wind=0.3,\n",
    "    \n",
    ")\n",
    "results_df_MAE = experiment.summarize_feature_group_results(metric='MAE')\n",
    "results_df_MSE = experiment.summarize_feature_group_results(metric='RMSE')\n",
    "results_df_time = experiment.summarize_feature_group_results(metric='elapsed_time')\n",
    "print('='*50)\n",
    "print(\"MAE:\")\n",
    "print(results_df_MAE)\n",
    "print(\"RMSE\")\n",
    "print(results_df_MSE)\n",
    "print(\"Elapsed time\")\n",
    "print(results_df_time)\n",
    "print('='*50)\n",
    "\n",
    "experiment.save_feature_group_results_to_csv(f\"../results/manipulate/point3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd3af34",
   "metadata": {},
   "source": [
    "# Experiment 4\n",
    "X reduction. Massive manipulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaac807",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataretreiver(reduce='pca_kmeans', debug=False, reduction_num_cols=12)\n",
    "df = data.combined\n",
    "# Initialize the experiment\n",
    "experiment = EnhancedTimeSeriesExperiment(\n",
    "    models=models,\n",
    "    target_column='price',\n",
    "    forecast_horizon=192,\n",
    "    n_splits=5,\n",
    "    step_size=192 # 8 days are skipped between each forecast.\n",
    ")\n",
    "# Run the experiments with these custom combinations\n",
    "experiment.run_feature_group_experiments(\n",
    "    df=df,\n",
    "    add_all_columns=True,\n",
    "    add_base_columns=False,\n",
    "    manipulate=True,\n",
    "    manipulate_factor_sun=0.5,\n",
    "    manipulate_factor_wind=0.5,\n",
    ")\n",
    "results_df_MAE = experiment.summarize_feature_group_results(metric='MAE')\n",
    "results_df_MSE = experiment.summarize_feature_group_results(metric='RMSE')\n",
    "results_df_time = experiment.summarize_feature_group_results(metric='elapsed_time')\n",
    "print('='*50)\n",
    "print(\"MAE:\")\n",
    "print(results_df_MAE)\n",
    "print(\"RMSE\")\n",
    "print(results_df_MSE)\n",
    "print(\"Elapsed time\")\n",
    "print(results_df_time)\n",
    "print('='*50)\n",
    "\n",
    "experiment.save_feature_group_results_to_csv(f\"../results/manipulate/ponit5.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
